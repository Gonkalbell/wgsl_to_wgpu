use std::{iter, sync::Arc};

use encase::UniformBuffer;
use futures::executor::block_on;
use wgpu::util::DeviceExt;
use winit::{application::ApplicationHandler, event::*, event_loop::EventLoop, window::Window};

// Include the bindings generated by build.rs.
// Not all of the binding code will be used.
#[allow(dead_code)]
mod compute_shader;
#[allow(dead_code)]
mod render_shaders;

// TODO: generate this
pub mod globals {
    pub mod color_texture {
        pub const GROUP: u32 = 0;
        pub const BINDING: u32 = 0;
        pub const LAYOUT: wgpu::BindGroupLayoutEntry = wgpu::BindGroupLayoutEntry {
            binding: BINDING,
            visibility: wgpu::ShaderStages::VERTEX_FRAGMENT,
            ty: wgpu::BindingType::Texture {
                sample_type: wgpu::TextureSampleType::Float { filterable: true },
                view_dimension: wgpu::TextureViewDimension::D2,
                multisampled: false,
            },
            count: None,
        };
        pub type Resource<'a> = &'a wgpu::TextureView;
        pub fn bind_group_entry(resource: Resource) -> wgpu::BindGroupEntry<'_> {
            wgpu::BindGroupEntry {
                binding: BINDING,
                resource: wgpu::BindingResource::TextureView(resource),
            }
        }
    }
    pub mod color_sampler {
        pub const GROUP: u32 = 0;
        pub const BINDING: u32 = 1;
        pub const LAYOUT: wgpu::BindGroupLayoutEntry = wgpu::BindGroupLayoutEntry {
            binding: BINDING,
            visibility: wgpu::ShaderStages::VERTEX_FRAGMENT,
            ty: wgpu::BindingType::Sampler(wgpu::SamplerBindingType::Filtering),
            count: None,
        };
        pub type Resource<'a> = &'a wgpu::Sampler;
        pub fn bind_group_entry(resource: Resource) -> wgpu::BindGroupEntry<'_> {
            wgpu::BindGroupEntry {
                binding: BINDING,
                resource: wgpu::BindingResource::Sampler(resource),
            }
        }
    }
    pub mod uniforms {
        pub const GROUP: u32 = 1;
        pub const BINDING: u32 = 0;
        pub const LAYOUT: wgpu::BindGroupLayoutEntry = wgpu::BindGroupLayoutEntry {
            binding: BINDING,
            visibility: wgpu::ShaderStages::VERTEX_FRAGMENT,
            ty: wgpu::BindingType::Buffer {
                ty: wgpu::BufferBindingType::Uniform,
                has_dynamic_offset: false,
                min_binding_size: None,
            },
            count: None,
        };
        pub type Resource<'a> = wgpu::BufferBinding<'a>;
        pub fn bind_group_entry(resource: Resource) -> wgpu::BindGroupEntry<'_> {
            wgpu::BindGroupEntry {
                binding: BINDING,
                resource: wgpu::BindingResource::Buffer(resource),
            }
        }
    }

    pub mod storage_vars {
        pub const GROUP: u32 = 0;
        pub const BINDING: u32 = 0;
        pub const LAYOUT: wgpu::BindGroupLayoutEntry = wgpu::BindGroupLayoutEntry {
            binding: BINDING,
            visibility: wgpu::ShaderStages::COMPUTE,
            ty: wgpu::BindingType::Buffer {
                ty: wgpu::BufferBindingType::Storage { read_only: false },
                has_dynamic_offset: false,
                min_binding_size: None,
            },
            count: None,
        };
        pub type Resource<'a> = wgpu::BufferBinding<'a>;
        pub fn bind_group_entry(resource: Resource) -> wgpu::BindGroupEntry<'_> {
            wgpu::BindGroupEntry {
                binding: BINDING,
                resource: wgpu::BindingResource::Buffer(resource),
            }
        }
    }
}

pub mod bind_groups {
    use super::globals;

    #[derive(Debug)]
    pub struct BindGroup0(pub wgpu::BindGroup);

    impl BindGroup0 {
        const INDEX: u32 = 0;
        const LAYOUT_DESCRIPTOR: wgpu::BindGroupLayoutDescriptor<'static> =
            wgpu::BindGroupLayoutDescriptor {
                label: Some("LayoutDescriptor0"),
                entries: &[
                    globals::color_texture::LAYOUT,
                    globals::color_sampler::LAYOUT,
                ],
            };

        pub fn create_bind_group_layout(device: &wgpu::Device) -> wgpu::BindGroupLayout {
            device.create_bind_group_layout(&Self::LAYOUT_DESCRIPTOR)
        }

        pub fn create(
            device: &wgpu::Device,
            color_texture: globals::color_texture::Resource,
            color_sampler: globals::color_sampler::Resource,
        ) -> Self {
            let bind_group_layout = Self::create_bind_group_layout(device);
            let bind_group = device.create_bind_group(&wgpu::BindGroupDescriptor {
                layout: &bind_group_layout,
                entries: &[
                    globals::color_texture::bind_group_entry(color_texture),
                    globals::color_sampler::bind_group_entry(color_sampler),
                ],
                label: Some("BindGroup0"),
            });
            Self(bind_group)
        }

        pub fn set_on_rpass<'a>(&'a self, render_pass: &mut impl wgpu::util::RenderEncoder<'a>) {
            render_pass.set_bind_group(Self::INDEX, &self.0, &[]);
        }

        pub fn set_on_cpass<'a>(&'a self, render_pass: &mut wgpu::ComputePass<'a>) {
            render_pass.set_bind_group(Self::INDEX, &self.0, &[]);
        }
    }

    #[derive(Debug)]
    pub struct BindGroup1(pub wgpu::BindGroup);

    impl BindGroup1 {
        const INDEX: u32 = 1;
        const LAYOUT_DESCRIPTOR: wgpu::BindGroupLayoutDescriptor<'static> =
            wgpu::BindGroupLayoutDescriptor {
                label: Some("LayoutDescriptor1"),
                entries: &[globals::uniforms::LAYOUT],
            };

        pub fn create_bind_group_layout(device: &wgpu::Device) -> wgpu::BindGroupLayout {
            device.create_bind_group_layout(&Self::LAYOUT_DESCRIPTOR)
        }

        pub fn from_bindings(device: &wgpu::Device, uniforms: globals::uniforms::Resource) -> Self {
            let bind_group_layout = Self::create_bind_group_layout(device);
            let bind_group = device.create_bind_group(&wgpu::BindGroupDescriptor {
                layout: &bind_group_layout,
                entries: &[globals::uniforms::bind_group_entry(uniforms)],
                label: Some("BindGroup1"),
            });
            Self(bind_group)
        }

        pub fn set_on_rpass<'a>(&'a self, render_pass: &mut impl wgpu::util::RenderEncoder<'a>) {
            render_pass.set_bind_group(Self::INDEX, &self.0, &[]);
        }
        pub fn set_on_cpass<'a>(&'a self, render_pass: &mut wgpu::ComputePass<'a>) {
            render_pass.set_bind_group(Self::INDEX, &self.0, &[]);
        }
    }

    #[derive(Debug)]
    pub struct CSBindGroup0(pub wgpu::BindGroup);

    impl CSBindGroup0 {
        const INDEX: u32 = 0;
        const LAYOUT_DESCRIPTOR: wgpu::BindGroupLayoutDescriptor<'static> =
            wgpu::BindGroupLayoutDescriptor {
                label: Some("LayoutDescriptor0"),
                entries: &[globals::storage_vars::LAYOUT],
            };

        pub fn create_bind_group_layout(device: &wgpu::Device) -> wgpu::BindGroupLayout {
            device.create_bind_group_layout(&Self::LAYOUT_DESCRIPTOR)
        }

        pub fn create(
            device: &wgpu::Device,
            storage_vars: globals::storage_vars::Resource,
        ) -> Self {
            let bind_group_layout = Self::create_bind_group_layout(device);
            let bind_group = device.create_bind_group(&wgpu::BindGroupDescriptor {
                layout: &bind_group_layout,
                entries: &[globals::storage_vars::bind_group_entry(storage_vars)],
                label: Some("BindGroup0"),
            });
            Self(bind_group)
        }

        pub fn set_on_rpass<'a>(&'a self, render_pass: &mut impl wgpu::util::RenderEncoder<'a>) {
            render_pass.set_bind_group(Self::INDEX, &self.0, &[]);
        }

        pub fn set_on_cpass<'a>(&'a self, render_pass: &mut wgpu::ComputePass<'a>) {
            render_pass.set_bind_group(Self::INDEX, &self.0, &[]);
        }
    }
}

struct State {
    window: Arc<Window>,
    surface: wgpu::Surface<'static>,
    device: wgpu::Device,
    queue: wgpu::Queue,
    size: winit::dpi::PhysicalSize<u32>,
    config: wgpu::SurfaceConfiguration,
    pipeline: wgpu::RenderPipeline,
    bind_group0: bind_groups::BindGroup0,
    bind_group1: bind_groups::BindGroup1,
    vertex_buffer: wgpu::Buffer,
    compute_pipeline: wgpu::ComputePipeline,
    compute_bind_group: bind_groups::CSBindGroup0,
}

impl State {
    async fn new(window: Window) -> Self {
        let window = Arc::new(window);
        let instance = wgpu::Instance::new(wgpu::InstanceDescriptor {
            backends: wgpu::Backends::all(),
            ..Default::default()
        });
        let surface = instance.create_surface(window.clone()).unwrap();
        let adapter = instance
            .request_adapter(&wgpu::RequestAdapterOptions {
                power_preference: wgpu::PowerPreference::default(),
                compatible_surface: Some(&surface),
                force_fallback_adapter: false,
            })
            .await
            .unwrap();

        // Push constants need to be enabled and have a requested max size.
        // 128 bytes is a reasonable limit to assume for desktop APIs.
        let (device, queue) = adapter
            .request_device(
                &wgpu::DeviceDescriptor {
                    label: None,
                    required_features: wgpu::Features::TEXTURE_COMPRESSION_BC
                        | wgpu::Features::PUSH_CONSTANTS,
                    required_limits: wgpu::Limits {
                        max_push_constant_size: 128,
                        ..Default::default()
                    },
                    memory_hints: Default::default(),
                },
                None,
            )
            .await
            .unwrap();

        let size = window.inner_size();
        let caps = surface.get_capabilities(&adapter);
        let surface_format = caps.formats[0];
        let config = surface
            .get_default_config(&adapter, size.width, size.height)
            .unwrap();
        surface.configure(&device, &config);

        // Use the generated bindings to create the pipeline.
        let module = render_shaders::create_shader_module(&device);
        let render_pipeline_layout = render_shaders::create_pipeline_layout(&device);

        // Set overrideable constant values or use render_shaders defaults if None.
        let overrides = render_shaders::OverrideConstants {
            force_black: false,
            scale: None,
        };

        let pipeline = device.create_render_pipeline(&wgpu::RenderPipelineDescriptor {
            label: Some("Render Pipeline"),
            layout: Some(&render_pipeline_layout),
            vertex: render_shaders::vertex_state(
                &module,
                &render_shaders::vs_main_entry(wgpu::VertexStepMode::Vertex, &overrides),
            ),
            fragment: Some(render_shaders::fragment_state(
                &module,
                &render_shaders::fs_main_entry([Some(surface_format.into())], &overrides),
            )),
            primitive: wgpu::PrimitiveState::default(),
            depth_stencil: None,
            multisample: wgpu::MultisampleState::default(),
            multiview: None,
            cache: Default::default(),
        });

        // Create a gradient texture.
        let texture = device.create_texture_with_data(
            &queue,
            &wgpu::TextureDescriptor {
                label: None,
                size: wgpu::Extent3d {
                    width: 4,
                    height: 4,
                    depth_or_array_layers: 1,
                },
                mip_level_count: 1,
                sample_count: 1,
                dimension: wgpu::TextureDimension::D2,
                format: wgpu::TextureFormat::Rgba8Unorm,
                usage: wgpu::TextureUsages::all(),
                view_formats: &[],
            },
            wgpu::util::TextureDataOrder::LayerMajor,
            bytemuck::cast_slice(&[
                [0u8, 0u8, 255u8, 255u8],
                [64u8, 0u8, 255u8, 255u8],
                [128u8, 0u8, 255u8, 255u8],
                [255u8, 0u8, 255u8, 255u8],
                [0u8, 64u8, 255u8, 255u8],
                [64u8, 64u8, 255u8, 255u8],
                [128u8, 64u8, 255u8, 255u8],
                [255u8, 64u8, 255u8, 255u8],
                [0u8, 128u8, 255u8, 255u8],
                [64u8, 128u8, 255u8, 255u8],
                [128u8, 128u8, 255u8, 255u8],
                [255u8, 128u8, 255u8, 255u8],
                [0u8, 255u8, 255u8, 255u8],
                [64u8, 255u8, 255u8, 255u8],
                [128u8, 255u8, 255u8, 255u8],
                [255u8, 255u8, 255u8, 255u8],
            ]),
        );

        let view = texture.create_view(&wgpu::TextureViewDescriptor::default());
        let sampler = device.create_sampler(&wgpu::SamplerDescriptor {
            mag_filter: wgpu::FilterMode::Linear,
            min_filter: wgpu::FilterMode::Linear,
            ..Default::default()
        });

        // Use the generated types to ensure the correct bind group is assigned to each slot.
        let bind_group0 = bind_groups::BindGroup0::create(&device, &view, &sampler);

        // wgsl_to_wgpu will generate alignment assertion checks when using bytemuck.
        // It's strongly recommended to use encase for uniform and storage buffers.
        // encase handles any size and alignment requirements at runtime.
        // This avoids any surprises with requirements like storage buffer offset alignment.
        let mut uniform_bytes = UniformBuffer::new(Vec::new());
        uniform_bytes
            .write(&render_shaders::Uniforms {
                // This value will be overwritten by the compute pass.
                color_rgb: glam::vec3(0.0, 0.0, 0.0),
            })
            .unwrap();

        let uniforms_buffer = device.create_buffer_init(&wgpu::util::BufferInitDescriptor {
            label: Some("uniforms"),
            contents: &uniform_bytes.into_inner(),
            usage: wgpu::BufferUsages::UNIFORM | wgpu::BufferUsages::STORAGE,
        });

        let bind_group1 = bind_groups::BindGroup1::from_bindings(
            &device,
            uniforms_buffer.as_entire_buffer_binding(),
        );

        // Initialize the vertex buffer based on the expected input structs.
        // For storage buffer compatibility, consider using encase instead.
        let vertex_buffer = device.create_buffer_init(&wgpu::util::BufferInitDescriptor {
            label: Some("vertex buffer"),
            contents: bytemuck::cast_slice(&[
                render_shaders::VertexInput {
                    position: glam::vec3(-1.0, -1.0, 0.0),
                },
                render_shaders::VertexInput {
                    position: glam::vec3(3.0, -1.0, 0.0),
                },
                render_shaders::VertexInput {
                    position: glam::vec3(-1.0, 3.0, 0.0),
                },
            ]),
            usage: wgpu::BufferUsages::VERTEX,
        });

        let compute_pipeline = compute_shader::compute::create_main_pipeline(&device);

        // Uniform and storage buffers both use the same memory layout for structs.
        // Applications that create offsets into storage buffers should use encase::StorageBuffer.
        let compute_bind_group =
            bind_groups::CSBindGroup0::create(&device, uniforms_buffer.as_entire_buffer_binding());

        Self {
            window,
            surface,
            device,
            queue,
            size,
            config,
            pipeline,
            bind_group0,
            bind_group1,
            vertex_buffer,
            compute_pipeline,
            compute_bind_group,
        }
    }

    pub fn resize(&mut self, new_size: winit::dpi::PhysicalSize<u32>) {
        if new_size.width > 0 && new_size.height > 0 {
            self.size = new_size;
            self.config.width = new_size.width;
            self.config.height = new_size.height;
            self.surface.configure(&self.device, &self.config);
        }
    }

    fn render(&mut self) -> Result<(), wgpu::SurfaceError> {
        let output = self.surface.get_current_texture()?;
        let output_view = output
            .texture
            .create_view(&wgpu::TextureViewDescriptor::default());

        let mut encoder = self
            .device
            .create_command_encoder(&wgpu::CommandEncoderDescriptor {
                label: Some("Render Encoder"),
            });

        let mut compute_pass = encoder.begin_compute_pass(&wgpu::ComputePassDescriptor {
            label: Some("Compute Pass"),
            timestamp_writes: None,
        });
        compute_pass.set_pipeline(&self.compute_pipeline);
        self.compute_bind_group.set_on_cpass(&mut compute_pass);
        compute_pass.dispatch_workgroups(1, 1, 1);
        drop(compute_pass);

        let mut render_pass = encoder.begin_render_pass(&wgpu::RenderPassDescriptor {
            label: Some("Render Pass"),
            color_attachments: &[Some(wgpu::RenderPassColorAttachment {
                view: &output_view,
                resolve_target: None,
                ops: wgpu::Operations {
                    load: wgpu::LoadOp::Clear(wgpu::Color::BLACK),
                    store: wgpu::StoreOp::Store,
                },
            })],
            depth_stencil_attachment: None,
            timestamp_writes: None,
            occlusion_query_set: None,
        });

        render_pass.set_pipeline(&self.pipeline);

        // Push constant data also needs to follow alignment rules.
        let mut push_constant_bytes = UniformBuffer::new(Vec::new());
        push_constant_bytes
            .write(&render_shaders::PushConstants {
                color_matrix: glam::Mat4::IDENTITY,
            })
            .unwrap();
        render_pass.set_push_constants(
            wgpu::ShaderStages::VERTEX_FRAGMENT,
            0,
            &push_constant_bytes.into_inner(),
        );

        self.bind_group0.set_on_rpass(&mut render_pass);
        self.bind_group1.set_on_rpass(&mut render_pass);

        render_pass.set_vertex_buffer(0, self.vertex_buffer.slice(..));
        render_pass.draw(0..3, 0..1);

        drop(render_pass);
        self.queue.submit(iter::once(encoder.finish()));

        // Actually draw the frame.
        output.present();

        Ok(())
    }
}

fn main() {
    let event_loop = EventLoop::new().unwrap();
    let mut app = App { state: None };
    event_loop.run_app(&mut app).unwrap();
}

struct App {
    state: Option<State>,
}

impl ApplicationHandler<()> for App {
    fn resumed(&mut self, event_loop: &winit::event_loop::ActiveEventLoop) {
        if self.state.is_some() {
            return;
        }

        let window = event_loop
            .create_window(Window::default_attributes().with_title("wgsl_to_wgpu"))
            .unwrap();

        self.state = Some(block_on(State::new(window)));
    }

    fn window_event(
        &mut self,
        event_loop: &winit::event_loop::ActiveEventLoop,
        window_id: winit::window::WindowId,
        event: WindowEvent,
    ) {
        if event == WindowEvent::CloseRequested {
            event_loop.exit();
            return;
        };

        // Window specific event handling.
        if let Some(state) = self.state.as_mut() {
            if window_id != state.window.id() {
                return;
            }

            match event {
                WindowEvent::Resized(physical_size) => {
                    state.resize(physical_size);
                    state.window.request_redraw();
                }
                WindowEvent::ScaleFactorChanged { .. } => {}
                WindowEvent::RedrawRequested => {
                    match state.render() {
                        Ok(_) => {}
                        Err(wgpu::SurfaceError::Lost) => state.resize(state.size),
                        Err(wgpu::SurfaceError::OutOfMemory) => event_loop.exit(),
                        Err(e) => eprintln!("{e:?}"),
                    }
                    state.window.request_redraw();
                }
                _ => {
                    state.window.request_redraw();
                }
            }
        }
    }
}
